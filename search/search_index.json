{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ezp","text":"<p><code>ezp</code> is a lightweight C++ wrapper for selected ScaLAPACK solvers for linear systems.</p>"},{"location":"#dependency","title":"Dependency","text":"<p>The <code>ezp</code> library is header only. The following drivers are needed.</p> <ol> <li>an implementation of <code>LAPACK</code> and <code>BLAS</code>, such as <code>OpenBLAS</code>, <code>MKL</code>, etc.</li> <li>an implementation of <code>ScaLAPACK</code></li> <li>an implementation of <code>MPI</code>, such as <code>OpenMPI</code>, <code>MPICH</code>, etc.</li> </ol>"},{"location":"#example","title":"Example","text":"<p>It is assumed that the root node (rank 0) prepares the left hand side \\(\\(A\\)\\) and right hand side \\(\\(B\\)\\). The solvers distrbute the matrices to available processes and solve the system, return the solution back to the master node.</p> <p>The solvers are designed in such a way that all <code>BLACS</code> and <code>ScaLAPACK</code> details are hidden. One shall prepare the matrices (on the root node) and call the solver. The following is a typical example. It highly resembles the sequential version of how one would typically solve a linear system.</p> C++<pre><code>#include &lt;ezp/pgesv.hpp&gt;\n#include &lt;iomanip&gt;\n#include &lt;iostream&gt;\n\nusing namespace ezp;\n\nint main() {\n    // get the current blacs environment\n    const auto rank = get_env&lt;int&gt;().rank();\n\n    constexpr auto N = 6, NRHS = 2;\n\n    // storage for the matrices A and B\n    std::vector&lt;double&gt; A, B;\n\n    if(0 == rank) {\n        // the matrices are only initialized on the root process\n        A.resize(N * N, 0.);\n        B.resize(N * NRHS, 1.);\n\n        // helper functor to convert 2D indices to 1D indices\n        const auto IDX = par_dgesv&lt;int&gt;::indexer{N};\n\n        for(auto I = 0; I &lt; N; ++I) A[IDX(I, I)] = static_cast&lt;double&gt;(I);\n    }\n\n    // create a parallel solver\n    // it takes the number of rows and columns of the process grid as arguments\n    // or let the library automatically determine as follows\n    // need to wrap the data in full_mat objects\n    // it requires the number of rows and columns of the matrix, and a pointer to the data\n    // on non-root processes, the data pointer is nullptr as the vector is empty\n    // par_dgesv&lt;int&gt;().solve(full_mat{N, N, A.data()}, full_mat{N, NRHS, B.data()});\n    par_dgesv&lt;int&gt;().solve({N, N, A.data()}, {N, NRHS, B.data()});\n\n    if(0 == rank) {\n        std::cout &lt;&lt; std::setprecision(10) &lt;&lt; \"Solution:\\n\";\n        for(auto i = 0; i &lt; B.size(); ++i) std::cout &lt;&lt; B[i] &lt;&lt; '\\n';\n    }\n\n    return 0;\n}\n</code></pre>"},{"location":"Guide/Standalone/","title":"Standalone Solver","text":"<p>MPI provides a mechanism to dynamically spawn worker processes via <code>MPI_Comm_spawn</code>. By utilising this feature, it is possible to separate the main application from the solver. The architecture can be illustrated as follows.</p> <p></p> <p>The <code>esp</code> solvers are also available as standalone executables that follow the above design. Such a form is particularly beneficial if the following holds.</p> <ol> <li>The main application is not suitable for distributed-memory model due to, for example, latency constraints.</li> <li>The main application adopts a different parallelism pattern.</li> <li>Sometimes, one may want to have a clear boundary between the main application and the solver(s).</li> </ol> <p>However, such a clear boundary may be a shortcoming as well. For example, the root process needs to store the whole matrices in memory, which is subject to physical limitations. And since the spawned processes are not persistent, solving the same system with different right-hand sides may incur unnecessary data communication.</p> <p>If the matrices need to be read from IO in a distributed manner, one may also need a refined control of how the data is prepared, by probably directly using <code>BLACS</code>/<code>ScaLAPACK</code>/<code>MPI</code> functions.</p>"},{"location":"Guide/Standalone/#backbone","title":"Backbone","text":"<p>Here, we use the <code>pgesv</code> solver as the example to illustrate some critical steps used in implementing the above architecture.</p> <p>We are not using the raw <code>MPI</code> functions, instead, the <code>mpl</code> library is used. It is necessary to get the default communicator and the parent inter communicator.</p> solver.pgesv.cpp:52:55<pre><code>#include &lt;mpl/mpl.hpp&gt;\n\nconst auto&amp; comm_world{mpl::environment::comm_world()};\nconst auto&amp; parent = mpl::inter_communicator::parent();\n</code></pre> <p>Since <code>mpl</code> handles <code>MPI</code> environment initialisation and finalisation, it is necessary to tell <code>ezp</code> to ignore finalising the <code>MPI</code> environment. The function <code>ezp::blacs_env::do_not_manage_mpi()</code> must be called if <code>MPI</code> is managed by external tools.</p> solver.pgesv.cpp:83<pre><code>    ezp::blacs_env&lt;int&gt;::do_not_manage_mpi();\n</code></pre> <p>The parameters of the linear system will be broadcast over by the main application first.</p> solver.pgesv.cpp:90:98<pre><code>    const auto all = mpl::communicator(parent, mpl::communicator::order_high);\n\n    int config[3]{};\n\n    all.bcast(0, config);\n\n    const auto N = config[0];\n    const auto NRHS = config[1];\n    const auto FLOAT = config[2];\n</code></pre> <p>Knowing the problem sizes <code>N</code> and <code>NRHS</code>, the root process can initialise the containers and receive the contents of two matrices.</p> solver.pgesv.cpp:60:70<pre><code>    if(0 == comm_world.rank()) {\n        A.resize(N * N);\n        B.resize(N * NRHS);\n\n        mpl::irequest_pool requests;\n\n        requests.push(parent.irecv(A, 0, mpl::tag_t{0}));\n        requests.push(parent.irecv(B, 0, mpl::tag_t{1}));\n\n        requests.waitall();\n    }\n</code></pre> <p>Solving the system follows the conventional approach, that is, create a solver object and call the solve method with data wrapped. The solution is sent back to the caller.</p> solver.pgesv.cpp:72:77<pre><code>    const auto error = ezp::pgesv&lt;DT, int&gt;().solve({N, N, A.data()}, {N, NRHS, B.data()});\n\n    if(0 == comm_world.rank()) {\n        parent.send(error, 0);\n        if(0 == error) parent.send(B, 0);\n    }\n</code></pre>"},{"location":"Guide/Standalone/#the-caller","title":"The Caller","text":"<p>From the above code snippets, one may observe that the caller needs to</p> <ol> <li>broadcast <code>config</code>,</li> <li>send <code>A</code> and <code>B</code>,</li> <li>receive the error code and the solution <code>X</code> if no error occured.</li> </ol> <p>To this end, one can declare the corresponding containers using <code>std::vector</code>.</p> runner.cpp:38:39<pre><code>    std::vector&lt;double&gt; A, B(N * NRHS, 1.);\n    std::vector&lt;int&gt; config;\n</code></pre> <p>The following creates a diagonal matrix for illustration.</p> runner.cpp:45:50<pre><code>        solver = \"solver.pgesv\";\n\n        config = {N, NRHS, 1};\n\n        A.resize(N * N, 0.);\n        for(auto I = 0; I &lt; N; ++I) A[I * N + I] = I + 1.;\n</code></pre> <p>Now since all the data is ready to be communicated, the actual communication is very concise and straightforward.</p> runner.cpp:95:110<pre><code>    const auto&amp; comm_world{mpl::environment::comm_world()};\n    const auto worker = comm_world.spawn(0, argc &lt; 3 ? 1 : std::abs(std::stoi(argv[2])), {solver});\n    const auto all = mpl::communicator(worker, mpl::communicator::order_low);\n\n    all.bcast(0, config.data(), mpl::contiguous_layout&lt;int&gt;(config.size()));\n\n    mpl::irequest_pool requests;\n\n    requests.push(worker.isend(A, 0, mpl::tag_t{0}));\n    requests.push(worker.isend(B, 0, mpl::tag_t{1}));\n\n    requests.waitall();\n\n    int error = -1;\n    worker.recv(error, 0);\n    if(0 == error) worker.recv(B, 0);\n</code></pre>"},{"location":"Guide/Standalone/#full-reference-implementation","title":"Full Reference Implementation","text":"<p>The following is a full reference implementation of a standalone solver and the corresponding caller logic.</p> runner.cpp<pre><code>/*******************************************************************************\n * Copyright (C) 2025 Theodore Chang\n *\n * This program is free software: you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation, either version 3 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.\n ******************************************************************************/\n/**\n * @brief Example caller to the standalone solvers.\n *\n * @author tlc\n * @date 07/03/2025\n * @version 1.0.0\n * @file runner.cpp\n * @{\n */\n\n#include &lt;iostream&gt;\n#include &lt;mpl/mpl.hpp&gt;\n\nint main(int argc, char** argv) {\n    if(argc &lt; 2) {\n        std::cout &lt;&lt; \"Usage: runner ge|po|gb|db|pb [n]\\n\";\n        std::cout &lt;&lt; \"Example: runner ge 3\\n\";\n        return 0;\n    }\n    constexpr auto N = 6, NRHS = 1;\n\n    std::vector&lt;double&gt; A, B(N * NRHS, 1.);\n    std::vector&lt;int&gt; config;\n\n    const auto type = std::string(argv[1]);\n    std::string solver;\n\n    if(\"ge\" == type) {\n        solver = \"solver.pgesv\";\n\n        config = {N, NRHS, 1};\n\n        A.resize(N * N, 0.);\n        for(auto I = 0; I &lt; N; ++I) A[I * N + I] = I + 1.;\n    }\n    else if(\"po\" == type) {\n        solver = \"solver.pposv\";\n\n        config = {N, NRHS, 1};\n\n        A.resize(N * N, 0.);\n        for(auto I = 0; I &lt; N; ++I) A[I * N + I] = I + 1.;\n    }\n    else if(\"gb\" == type) {\n        solver = \"solver.pgbsv\";\n\n        constexpr auto KL = 1, KU = 1;\n\n        config = {N, KL, KU, NRHS, 1};\n\n        A.resize(N * (KL + KU + 1), 0.);\n        for(auto I = 0; I &lt; N; ++I) A[KU + I * (KL + KU + 1)] = I + 1.;\n    }\n    else if(\"db\" == type) {\n        solver = \"solver.pdbsv\";\n\n        constexpr auto KL = 1, KU = 1;\n\n        config = {N, KL, KU, NRHS, 1};\n\n        A.resize(N * (KL + KU + 1), 0.);\n        for(auto I = 0; I &lt; N; ++I) A[KU + I * (KL + KU + 1)] = I + 1.;\n    }\n    else if(\"pb\" == type) {\n        solver = \"solver.ppbsv\";\n\n        constexpr auto KLU = 1;\n\n        config = {N, KLU, NRHS, 1};\n\n        A.resize(N * (KLU + 1), 0.);\n        for(auto I = 0; I &lt; N; ++I) A[I + I * KLU] = I + 1.;\n    }\n    else {\n        std::cout &lt;&lt; \"Usage: runner ge|po|gb|db|pb [n]\\n\";\n        return 0;\n    }\n\n    const auto&amp; comm_world{mpl::environment::comm_world()};\n    const auto worker = comm_world.spawn(0, argc &lt; 3 ? 1 : std::abs(std::stoi(argv[2])), {solver});\n    const auto all = mpl::communicator(worker, mpl::communicator::order_low);\n\n    all.bcast(0, config.data(), mpl::contiguous_layout&lt;int&gt;(config.size()));\n\n    mpl::irequest_pool requests;\n\n    requests.push(worker.isend(A, 0, mpl::tag_t{0}));\n    requests.push(worker.isend(B, 0, mpl::tag_t{1}));\n\n    requests.waitall();\n\n    int error = -1;\n    worker.recv(error, 0);\n    if(0 == error) worker.recv(B, 0);\n\n    for(auto I = 0; I &lt; N; ++I) printf(\"x[%d] = %+.6f\\n\", I, B[I]);\n\n    return 0;\n}\n\n//! @}\n</code></pre> solver.pgesv.cpp<pre><code>/*******************************************************************************\n * Copyright (C) 2025 Theodore Chang\n *\n * This program is free software: you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation, either version 3 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.\n ******************************************************************************/\n/**\n * @brief Standalone `pgesv` solver.\n *\n * This program is a standalone application that solves a system of linear equations\n * using the `pgesv` solver.\n *\n * The caller spawns this program as a worker process.\n *\n * The caller must send three buffers to the worker process:\n * - an integer array of size 3 containing the matrix size (`N`),\n *   number of right-hand sides (`NRHS`), and the data type,\n * - a buffer containing the matrix `A`, size `N x N`,\n * - a buffer containing the right-hand side `B`, size `N x NRHS`.\n *\n * The data type has the following meaning:\n * - 2-digit positive: complex16,\n * - 1-digit positive: double,\n * - 1-digit negative: float,\n * - 2-digit negative: complex8.\n *\n * The error code (0 for success) will be sent back to the root process of the caller.\n * If error code is 0, the solution will be sent back as well.\n *\n * The example caller logic can be seen as follows.\n *\n * @include runner.cpp\n *\n * @author tlc\n * @date 07/03/2025\n * @version 1.0.0\n * @file solver.pgesv.cpp\n * @{\n */\n\n#include &lt;ezp/pgesv.hpp&gt;\n#include &lt;mpl/mpl.hpp&gt;\n\nconst auto&amp; comm_world{mpl::environment::comm_world()};\nconst auto&amp; parent = mpl::inter_communicator::parent();\n\ntemplate&lt;ezp::data_t DT&gt; int run(const int N, const int NRHS) {\n    std::vector&lt;DT&gt; A, B;\n\n    if(0 == comm_world.rank()) {\n        A.resize(N * N);\n        B.resize(N * NRHS);\n\n        mpl::irequest_pool requests;\n\n        requests.push(parent.irecv(A, 0, mpl::tag_t{0}));\n        requests.push(parent.irecv(B, 0, mpl::tag_t{1}));\n\n        requests.waitall();\n    }\n\n    const auto error = ezp::pgesv&lt;DT, int&gt;().solve({N, N, A.data()}, {N, NRHS, B.data()});\n\n    if(0 == comm_world.rank()) {\n        parent.send(error, 0);\n        if(0 == error) parent.send(B, 0);\n    }\n\n    return 0;\n}\n\nint main(int argc, char** argv) {\n    ezp::blacs_env&lt;int&gt;::do_not_manage_mpi();\n\n    if(!parent.is_valid()) {\n        printf(\"This program must be invoked by the host application.\\n\");\n        return 0;\n    }\n\n    const auto all = mpl::communicator(parent, mpl::communicator::order_high);\n\n    int config[3]{};\n\n    all.bcast(0, config);\n\n    const auto N = config[0];\n    const auto NRHS = config[1];\n    const auto FLOAT = config[2];\n\n    if(FLOAT &gt;= 10) return run&lt;complex16&gt;(N, NRHS);\n    if(FLOAT &gt;= 0) return run&lt;double&gt;(N, NRHS);\n    if(FLOAT &gt; -10) return run&lt;float&gt;(N, NRHS);\n\n    return run&lt;complex8&gt;(N, NRHS);\n}\n\n//! @}\n</code></pre>"},{"location":"Intro/Compilation/","title":"Compilation","text":"<p>As <code>ezp</code> is wrapper library of <code>ScaLAPACK</code>, the following dependencies are necessary to compile any executables that use <code>ezp</code>.</p> <ol> <li>an implementation of <code>LAPACK</code> and <code>BLAS</code>, such as <code>OpenBLAS</code>, <code>Intel\u00ae oneAPI Math Kernel Library (oneMKL)</code>, <code>AMD Optimizing CPU Libraries (AOCL)</code>, etc.</li> <li>an implementation of <code>ScaLAPACK</code>, such as the reference implementation, Intel's implementation, NVIDIA's implementation, etc.</li> <li>an implementation of <code>MPI</code>, such as <code>OpenMPI</code>, <code>MPICH</code>, <code>Intel\u00ae MPI</code> etc.</li> </ol> <p>Before compiling the executables, one must ensure those libraries are available.</p>"},{"location":"Intro/Compilation/#oneapi","title":"oneAPI","text":"<p>The easiest approach is to use the <code>Intel\u00ae oneAPI</code> toolkit. It provides the <code>Intel\u00ae MPI Library</code> and the <code>Intel\u00ae oneAPI Math Kernel Library (oneMKL)</code> which contains a complete <code>ScaLAPACK</code> and <code>LAPACK</code>/<code>BLAS</code> implementation.</p> <p>The following is a sample workflow that runs on <code>Fedora</code>.</p> Bash<pre><code>echo -e \"[oneAPI]\\nname=Intel\u00ae oneAPI repository\\nbaseurl=https://yum.repos.intel.com/oneapi\\nenabled=1\\ngpgcheck=1\\nrepo_gpgcheck=1\\ngpgkey=https://yum.repos.intel.com/intel-gpg-keys/GPG-PUB-KEY-INTEL-SW-PRODUCTS.PUB\" &gt; /etc/yum.repos.d/oneAPI.repo\n\nsudo dnf install -y intel-oneapi-mkl-devel intel-oneapi-mpi-devel cmake gcc g++ gfortran git ninja-build\n\ngit clone --recurse-submodules --depth 1 https://github.com/TLCFEM/ezp.git\n\nmkdir /ezp/build &amp;&amp; /ezp/build\n\n. /opt/intel/oneapi/setvars.sh &amp;&amp; cmake -DEZP_TEST=ON .. &amp;&amp; cmake --build . --config Release\n</code></pre>"},{"location":"Intro/Compilation/#system-libraries","title":"System Libraries","text":"<p>Using system libraries is possible but most bundled libraries are broken on various distros. One then needs to manually compile all those depedencies before using them. This is cumbersome.</p> <p><code>Fedora 41</code> has an environment that is closest to usable. The following is an example that uses system packages.</p> Bash<pre><code>sudo dnf install -y cmake gcc g++ gfortran git ninja-build scalapack-mpich-devel flexiblas-devel\n# sadly the scalapack package is broken on fedora 41\n# need to provide this link\nsudo ln -s /usr/lib64/mpich/lib/libscalapack.so.2.2.0 /usr/lib64/libscalapack.so.2.2.0\n\ngit clone --recurse-submodules --depth 1 https://github.com/TLCFEM/ezp.git\n\nmkdir /ezp/build &amp;&amp; /ezp/build\n\ncmake -DEZP_TEST=ON -DMPI_HOME=/usr/lib64/mpich/ -DEZP_USE_SYSTEM_LIBS=ON .. &amp;&amp; cmake --build . --config Release\n</code></pre>"},{"location":"Intro/Motivation/","title":"Motivation","text":""}]}